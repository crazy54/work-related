{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "webinar",
      "language": "python",
      "name": "webinar"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "[webinar] Hands-on Data Analysis with Python-student_nb.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crazy54/work-related/blob/master/%5Bwebinar%5D_Hands_on_Data_Analysis_with_Python_student_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGykOr5kZ8t3"
      },
      "source": [
        "# TITLE:  Karting Through Video Games History with Python: how to manipulate your data from Zelda to CoD\n",
        "## Author: Andrea Giussani - Data Scientist at Cloud Academy\n",
        "### Date: Nov 12, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MruAMA2bZ8t5"
      },
      "source": [
        "Have you ever wondered what is the most played video game in the last thirty years? How about which gaming platform is the most used in the last decade?\n",
        "\n",
        "In this hands-on webinar, we are going to explore advanced data manipulation techniques that are typically used to translate raw data into insightful plots and charts — enabling you to answer these types of questions. To perform this analysis, we will use Python and we will explore two of the most important data analytics libraries: Pandas and Matplotlib.\n",
        "\n",
        "To get the most out of this webinar, we encourage some familiarity with Python, although extensive experience with the language would be best. For those who are new to Python, you can get your feet wet with the following Cloud Academy courses:\n",
        "\n",
        "* Working with Python\n",
        "* Python Functions, Modules, and Packages\n",
        "* Data Wrangling with Pandas\n",
        "\n",
        "By the end of this webinar, the participants will be able to:\n",
        "\n",
        "* Understand the main functionalities of Pandas for data manipulation\n",
        "* Plot raw data into nice looking charts in Python using Matplotlib\n",
        "* Complete a data analytics pipeline for exploratory data analysis\n",
        "\n",
        "Participants are strongly encouraged to download the necessary data from the following [Github repo](https://github.com/cloudacademy/ca_webinar_video_games_analysis).\n",
        "\n",
        "You can follow along with the webinar by using either your favorite local Python or Google Colab environment. For more details, please check the readme on the aforementioned Github repo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxypUlVYZ8t5"
      },
      "source": [
        "# IF YOU ARE RUNNING THIS NOTEBOOK VIA GOOGLE COLAB, PLEASE UNCOMMENT and RUN THIS CELL\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8V8FHCtZ8t9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reyg2sjRZ8uA"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDbWCFX5Z8uC"
      },
      "source": [
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 500)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9dXZOazZ8uF"
      },
      "source": [
        "## 1. Data Manipulation and Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d-_rczgZ8uF"
      },
      "source": [
        "### 1.1 Data Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J0h5tyhZ8uG"
      },
      "source": [
        "We read the file `'data/vgsales.csv'` using the pandas `read_csv()` function, and store it into the variable `data`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWv-Nz1fZ8uG"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/My Drive/ca.webinars/zelda/data/vgsales.csv')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ooj3JQqZ8uI"
      },
      "source": [
        "We now check the overall composition of the dataset using the `.info()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6wM3CFoZ8uJ",
        "outputId": "981ddaf4-00f8-45f0-a009-bcc8391e3f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16598 entries, 0 to 16597\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Rank          16598 non-null  int64  \n",
            " 1   Name          16598 non-null  object \n",
            " 2   Platform      16598 non-null  object \n",
            " 3   Year          16327 non-null  float64\n",
            " 4   Genre         16598 non-null  object \n",
            " 5   Publisher     16540 non-null  object \n",
            " 6   NA_Sales      16598 non-null  float64\n",
            " 7   EU_Sales      16598 non-null  float64\n",
            " 8   JP_Sales      16598 non-null  float64\n",
            " 9   Other_Sales   16598 non-null  float64\n",
            " 10  Global_Sales  16598 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(4)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6ycSSXwZ8uN"
      },
      "source": [
        "### 1.2 Data Cleaning\n",
        "\n",
        "We clearly see there exists a few null values among both the `Publisher` and `Year` columns. The strategy here is to remove them. <br>\n",
        "Let us remove the null values using the pandas `.dropna()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e2VMj6UZ8uO"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeJYZGlRZ8uT"
      },
      "source": [
        "The dataset was generated at the end of the year 2016. Hence, each observation with an occurrence greater than or equal to 2017 must be considered as either corrupted or incorrect, and hence must be removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCdUDbJQZ8uU"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Reqo__GoZ8uW"
      },
      "source": [
        "### 1.3 Data Consistency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAYQumapZ8uX"
      },
      "source": [
        "Before moving to a proper data analysis, we need to be sure the data is consistent. By consistency I mean an intrinsic characteristic of the data. For instance, the `Publisher` name might contain a typo, or sometimes a Publisher might be identified by several names. \n",
        "\n",
        "To investigate this, let us check how `Sony` appears inside our dataset: we hence access to the `Publisher` column, which is of type object, and try to check the different names `Sony` is used for: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0sLwZohZ8uX"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq4YCOCOZ8ua"
      },
      "source": [
        "Obviously, the Sony Publisher identifier is not homogeneously identified among observations.\n",
        "\n",
        "We might think of, say, changing `“Sony Computer Entertainment”`, `“Sony Computer Entertainment America”`, `“Sony Computer Entertainment Europe”`, `“Sony Music Entertainment”` and `“Sony Online Entertainment”` to `“Sony”`.\n",
        "\n",
        "To do this, we basically create a custom method, called `merging_info_publisher`, that should be called whenever we wish to perform such kind of cleaning on our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjTTM9nDZ8ua"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "def merging_info_publisher(data: pd.DataFrame, publisher: str):\n",
        "    data.loc[data['Publisher'].str.contains(publisher, case=False), 'Publisher'] = publisher\n",
        "    return data[data['Publisher'].str.contains(publisher, case=False)]['Publisher'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7iZE5KRZ8ud"
      },
      "source": [
        "Possibly, this pattern is repeated for different publishers as well. Here we identify a few Publishers that might have different labels inside the dataset, and we apply the `merging_info_publisher` method for each of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpuhDRVcZ8ud"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "publishers = ['Sony', 'Nintendo', 'Ubisoft', 'Activision', 'Electronic Arts', 'Konami']\n",
        "for publisher in publishers:\n",
        "    merging_info_publisher(data, publisher)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erWeEbgAZ8ug"
      },
      "source": [
        "Let us check now how `\"Sony\"` is mapped inside our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp_4XyARZ8ug"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "data[data['Publisher'].str.contains('Sony')]['Publisher'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flI-Y590Z8uj"
      },
      "source": [
        "An extra control is to convert `EA Sports` to `Electronic Arts`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aP5CIZBZ8uk"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "data.loc[data['Publisher'].str.contains('EA Sports', case=False), 'Publisher'] = 'Electronic Arts'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8dKdYhJZ8un"
      },
      "source": [
        "Also, convert `['Bandai', 'Namco Bandai', 'Namco', 'Namco Bandai Games' ]` to `Namco`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXEpQMYyZ8un"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "namco_names = ['Bandai', 'Namco Bandai', 'Namco', 'Namco Bandai Games' ]\n",
        "data.loc[data['Publisher'].str.contains('|'.join(namco_names), case=False), 'Publisher'] = 'Namco'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2qRLswSZ8up"
      },
      "source": [
        "Let us check the absolute distribution of the top 20 Publishers in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oekqnZ5KZ8uq"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0N3HFVBZ8us"
      },
      "source": [
        "Finally, remove the Publisher called `\"Unknown\"`: this is not obviously fine. Store the result into the global variable `filtered_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyMw2owZ8us"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N_AjNIPZ8uu"
      },
      "source": [
        "## 2. Total Games Released Each Year\n",
        "\n",
        "We now want to know when the video game industry experienced a drastic development. Based on the number of games released each year, we might be able to find out when the video games boom happened. We store the distribution of video games releases by year inside the variable `counter_df_by_year`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNenArIPZ8uu"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws7p1HtKZ8uw"
      },
      "source": [
        "Let us embed that dataframe into a graphical dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSOMriwHZ8ux"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Number of Games')\n",
        "ax.set_title('Evolution of Video Games Industry')\n",
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FPZeaQcZ8u0"
      },
      "source": [
        "There was a significant boom in the late 2000s. Since then, the distinct number of release has shrunk possibly due to a more convergence to popular titles by both customers and developers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze0W_XPAZ8u1"
      },
      "source": [
        "## 3. Publisher Analysis with respect to Global Sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Smp9WjnZ8u1"
      },
      "source": [
        "Instead of considering absolute frequencies (with respect to the number of video games releases) of the top publishers, a better proxy is to consider the top publishers by Global Sales, identified by the columns `\"Global_sales\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aY5PZlsZ8u2"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "total_sales_df = filtered_data[['Global_Sales', 'Publisher']].drop_duplicates().groupby('Publisher').sum()\n",
        "top_10_sales = total_sales_df.sort_values(by='Global_Sales', ascending=False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhB3Szu6Z8u4"
      },
      "source": [
        "### 3.2 Graphical Representation of the Publishers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIEg6RtgZ8u4"
      },
      "source": [
        "We again embed the above dataset into a graphical dimension to better understand the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA6G6ef0Z8u4"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtU5SwFZ8u6"
      },
      "source": [
        "## 4. Understand the most popular Platform by Year "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidePrompt": false,
        "id": "qAWCMuyYZ8u7"
      },
      "source": [
        "We now want to go further and try to see which Platform was the most popular for each Year. To do so, we again use a proxy the total Global Sales with respect to video games for each specific Platform. \n",
        "\n",
        "However, this requires a little bit of data wrangling, and therefore we need to perform a few steps to be able to answer to this question.\n",
        "\n",
        "First of all, we count the number of video games by Platform using the `.groupby()` method, and we store the result into the variable `most_popular_platforms`. This has been done for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zunVTQe8Z8u7"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "most_popular_platforms = filtered_data[['Name','Platform']].drop_duplicates().groupby('Platform').count()\n",
        "most_popular_platforms.rename(columns={'Name': 'Total Observations'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex1OTqt0Z8u9"
      },
      "source": [
        "We then need two steps:\n",
        "* store inside the variable `top20_platforms` the top 20 platform with respect to the column `Total Observations`;\n",
        "* filter the `filtered_data` with those Platforms. Store the result into `filtered_data_top20`.\n",
        "\n",
        "This has been done for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMvJxvAVZ8u9"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "top_20_platforms = most_popular_platforms.sort_values(by='Total Observations', ascending=False).head(20)\n",
        "filtered_data_top20 = filtered_data[filtered_data['Platform'].isin(list(top_20_platforms.index))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtAdyCIeZ8vB"
      },
      "source": [
        "We aggregate the data with respect to Global Sales using the pandas `.pivot_table()`. We would like to have, as columns, the platforms' vendor and, as index, the year. Store the result into the `pivoted_data_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU72ac2HZ8vB"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCeSI5QXZ8vE"
      },
      "source": [
        "The next part is a little bit tricky and it has been already prefilled for you. \n",
        "We now want to find the `Platform` which has the top sell for each distinct year. To do that we employ the `NumPy` method `argsort()` which basically allows to sort, for each row, the observations in ascending order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSRKav_SZ8vE"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "rows_arrangement = np.argsort(-pivoted_data_df.values, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub4Qu2nZ8vJ"
      },
      "source": [
        "We then select the column names based on the sorting operation, so that in the first place we will find the platform with highest value with respect to the aggregated Global Sales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fSSU6GyZ8vK"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "data_platform_by_year = pd.DataFrame(pivoted_data_df.columns[rows_arrangement], index=pivoted_data_df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmuoP5UtZ8vM"
      },
      "source": [
        "### 4.1 Distribution of the most popular platforms during the last 40 years"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mswBw2lFZ8vN"
      },
      "source": [
        "Store the results inside the variable `most_popular_platform_by_year`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpS6gUyCZ8vN"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMDDlXNxZ8vP"
      },
      "source": [
        "## 5. Which was the most popular game in each Year?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-4uipaLZ8vP"
      },
      "source": [
        "Store the resulting dataframe object into the variable `most_popular_games`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXlvqay0Z8vQ"
      },
      "source": [
        "# DO NOT REMOVE! THIS HAS BEEN PREFILLED FOR YOU\n",
        "most_popular_games = pd.DataFrame()\n",
        "\n",
        "for _, row in most_popular_platform_by_year.iterrows():\n",
        "    year = row['Year']\n",
        "    platform = row['Platform']\n",
        "    \n",
        "    inner_df = filtered_data.query(\"Year == @year & Platform==@platform\")\n",
        "    \n",
        "    pivoted_table_year_platform = inner_df.pivot_table(\n",
        "        index = 'Year',\n",
        "        columns='Name',\n",
        "        values='Global_Sales',\n",
        "        aggfunc='sum',\n",
        "        fill_value=0\n",
        "    )\n",
        "    \n",
        "    temp_col_max_value = pivoted_table_year_platform.max(axis=1).to_frame() # finds max value by row\n",
        "    temp_col_max_value.rename(columns={0:'Total sells (ML of units)'}, inplace=True)\n",
        "    \n",
        "    temp_col_max = pivoted_table_year_platform.idxmax(axis=1).to_frame() # find the column with the greatest value on each row\n",
        "    temp_col_max.rename(columns={0:'Most Wanted Title'}, inplace=True)\n",
        "    \n",
        "    merging_dfs = pd.concat([temp_col_max, temp_col_max_value], axis=1)\n",
        "    \n",
        "    most_popular_games = most_popular_games.append(merging_dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Sm7WdOZ8vR"
      },
      "source": [
        "## 6. Which was the most sold Title by Platform?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01YFBO2lZ8vS"
      },
      "source": [
        "Create a new object, called `most_popular_vg_by_platform`, that join the information from `most_popular_platfrom_by_year` and `most_popular_games`. Print the result in console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m52QgyDGZ8vU"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08WVgpVXZ8vY"
      },
      "source": [
        "## 7. Which are the most sold videogames ever?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKyRXzsRZ8vY"
      },
      "source": [
        "We are interesting in investigating which were the most sold titles in the last 40 years. To do so, we employ the `.groupby()` method, and store the result into the `most_wanted_vg` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npeokAiwZ8vY"
      },
      "source": [
        "# -------------------------------------------\n",
        "# TO BE FILLED\n",
        "# -------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEnBROLqZ8vd"
      },
      "source": [
        "It looks like the nintendo games are the most sold! The Wii sports was such a huge success for Nintendo. The classic “Mario” games own 4 of Top 10 most popular games."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQUgemAsZ8vd"
      },
      "source": [
        "## END"
      ]
    }
  ]
}